{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac0f574c",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1427312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e070c1ac",
   "metadata": {},
   "source": [
    "## 1. MixWaveUNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e582500",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4435a854",
   "metadata": {},
   "source": [
    "## 2. Differentiable Mixing Console (DMC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8933c280",
   "metadata": {},
   "outputs": [],
   "source": [
    "from automix.models.dmc import PostProcessor, Mixer, ShortChunkCNN_Res\n",
    "from automix.utils import restore_from_0to1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60b171b",
   "metadata": {},
   "source": [
    "Create the main modules of the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6199369b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/cjs01/code/automix-toolkit/env/lib/python3.9/site-packages/torchaudio/functional/functional.py:539: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (257) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded weights from ../checkpoints/encoder.ckpt\n"
     ]
    }
   ],
   "source": [
    "sample_rate = 44100\n",
    "mixer = Mixer(sample_rate)\n",
    "encoder = ShortChunkCNN_Res(sample_rate,ckpt_path=\"../checkpoints/encoder.ckpt\")\n",
    "post_processor = PostProcessor(mixer.num_params, encoder.d_embed * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294d8a58",
   "metadata": {},
   "source": [
    "The `forward()` function describes how to generate a mix using the subsystems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "096d3e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, x: torch.Tensor, track_mask: torch.Tensor = None):\n",
    "        \"\"\"Given a set of tracks, analyze them with a shared encoder, predict a set of mixing parameters,\n",
    "        and use these parameters to generate a stereo mixture of the inputs.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tracks with shape (bs, num_tracks, seq_len)\n",
    "            track_mask (torch.Tensor, optional): Mask specifying inactivate tracks with shape (bs, num_tracks)\n",
    "\n",
    "        Returns:\n",
    "            y (torch.Tensor): Final stereo mixture with shape (bs, 2, seq_len)\n",
    "            p (torch.Tensor): Estimated (denormalized) mixing parameters with shape (bs, num_tracks, num_params)\n",
    "        \"\"\"\n",
    "        bs, num_tracks, seq_len = x.size()\n",
    "\n",
    "        # move tracks to the batch dimension to fully parallelize embedding computation\n",
    "        x = x.view(bs * num_tracks, -1)\n",
    "\n",
    "        # generate single embedding for each track\n",
    "        e = self.encoder(x)\n",
    "        e = e.view(bs, num_tracks, -1)  # (bs, num_tracks, d_embed)\n",
    "\n",
    "        # generate the \"context\" embedding\n",
    "        c = e.mean(dim=1, keepdim=True)  # (bs, 1, d_embed)\n",
    "        c = c.repeat(1, num_tracks, 1)  # (bs, num_tracks, d_embed)\n",
    "\n",
    "        # fuse the track embs and context embs\n",
    "        ec = torch.cat((e, c), dim=-1)  # (bs, num_tracks, d_embed*2)\n",
    "\n",
    "        # estimate mixing parameters for each track (in parallel)\n",
    "        p = self.post_processor(ec)  # (bs, num_tracks, num_params)\n",
    "\n",
    "        # generate the stereo mix\n",
    "        x = x.view(bs, num_tracks, -1)  # move tracks back from batch dim\n",
    "        y, p = self.mixer(x, p)  # (bs, 2, seq_len) # and denormalized params\n",
    "\n",
    "        return y, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c7ca586",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "num_tracks = 8\n",
    "num_samples = 131072\n",
    "\n",
    "x = torch.randn(batch_size, num_tracks, num_samples)\n",
    "bs, num_tracks, seq_len = x.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfbb620",
   "metadata": {},
   "source": [
    "### 1. Generating embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec794e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We get 2x8 items in first dim: torch.Size([16, 131072])\n",
      "We get 8 embeddings of size 512: torch.Size([2, 8, 512])\n"
     ]
    }
   ],
   "source": [
    "# move tracks to the batch dimension to fully parallelize embedding computation\n",
    "x = x.view(bs * num_tracks, -1)\n",
    "print(f\"We get {bs}x{num_tracks} items in first dim: {x.shape}\")\n",
    "\n",
    "# generate single embedding for each track\n",
    "e = encoder(x)\n",
    "e = e.view(bs, num_tracks, -1)  # (bs, num_tracks, d_embed\n",
    "print(f\"We get {num_tracks} embeddings of size {encoder.d_embed}: {e.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bf41ad",
   "metadata": {},
   "source": [
    "### 2. \"Context\" embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cbbdfd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the \"context\" embedding\n",
    "c = e.mean(dim=1, keepdim=True)  # (bs, 1, d_embed)\n",
    "c = c.repeat(1, num_tracks, 1)  # (bs, num_tracks, d_embed)\n",
    "\n",
    "# fuse the track embs and context embs\n",
    "ec = torch.cat((e, c), dim=-1)  # (bs, num_tracks, d_embed*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55bce8b",
   "metadata": {},
   "source": [
    "### 3. Estimate mixing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9cce9654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate mixing parameters for each track (in parallel)\n",
    "p = post_processor(ec)  # (bs, num_tracks, num_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a99a276",
   "metadata": {},
   "source": [
    "### 4. Generate the mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e1442e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mix(x: torch.Tensor, p: torch.Tensor):\n",
    "    \"\"\"Generate a mix of stems given mixing parameters normalized to (0,1).\n",
    "\n",
    "    Args:\n",
    "        x (torch.Tensor): Batch of waveform stem tensors with shape (bs, num_tracks, seq_len).\n",
    "        p (torch.Tensor): Batch of normalized mixing parameters (0,1) for each stem with shape (bs, num_tracks, num_params)\n",
    "\n",
    "    Returns:\n",
    "        y (torch.Tensor): Batch of stereo waveform mixes with shape (bs, 2, seq_len)\n",
    "    \"\"\"\n",
    "    bs, num_tracks, seq_len = x.size()\n",
    "    \n",
    "    min_gain_dB = -48.0\n",
    "    max_gain_dB = 24.0\n",
    "\n",
    "    # ------------- apply gain -------------\n",
    "    gain_dB = p[..., 0]  # get gain parameter\n",
    "    gain_dB = restore_from_0to1(gain_dB, min_gain_dB, max_gain_dB)\n",
    "    gain_lin = 10 ** (gain_dB / 20.0)  # convert gain from dB scale to linear\n",
    "    gain_lin = gain_lin.view(bs, num_tracks, 1)  # reshape for multiplication\n",
    "    x = x * gain_lin  # apply gain (bs, num_tracks, seq_len)\n",
    "\n",
    "    # ------------- apply panning -------------\n",
    "    # expand mono stems to stereo, then apply panning\n",
    "    x = x.view(bs, num_tracks, 1, -1)  # (bs, num_tracks, 1, seq_len)\n",
    "    x = x.repeat(1, 1, 2, 1)  # (bs, num_tracks, 2, seq_len)\n",
    "\n",
    "    pan = p[..., 1]  # get pan parameter\n",
    "    pan_theta = pan * torch.pi / 2\n",
    "    left_gain = torch.cos(pan_theta)\n",
    "    right_gain = torch.sin(pan_theta)\n",
    "    pan_gains_lin = torch.stack([left_gain, right_gain], dim=-1)\n",
    "    pan_gains_lin = pan_gains_lin.view(bs, num_tracks, 2, 1)  # reshape for multiply\n",
    "    x = x * pan_gains_lin  # (bs, num_tracks, 2, seq_len)\n",
    "\n",
    "    # ----------------- apply mix -------------\n",
    "    # generate a mix for each batch item by summing stereo tracks\n",
    "    y = torch.sum(x, dim=1)  # (bs, 2, seq_len)\n",
    "\n",
    "    p = torch.cat(\n",
    "        (\n",
    "            gain_dB.view(bs, num_tracks, 1),\n",
    "            pan.view(bs, num_tracks, 1),\n",
    "        ),\n",
    "        dim=-1,\n",
    "    )\n",
    "\n",
    "    return y, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f6cd3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the stereo mix\n",
    "x = x.view(bs, num_tracks, -1)  # move tracks back from batch dim\n",
    "y, p = generate_mix(x, p)  # (bs, 2, seq_len) # and denormalized params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4eabf8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 gain dB:-12.856  pan:0.501\n",
      "1 gain dB:-12.848  pan:0.501\n",
      "2 gain dB:-12.841  pan:0.501\n",
      "3 gain dB:-12.850  pan:0.501\n",
      "4 gain dB:-12.849  pan:0.501\n",
      "5 gain dB:-12.857  pan:0.501\n",
      "6 gain dB:-12.861  pan:0.501\n",
      "7 gain dB:-12.854  pan:0.501\n"
     ]
    }
   ],
   "source": [
    "for tidx, track_params in enumerate(p[0,...]):\n",
    "    print(f\"{tidx} gain dB:{track_params[0]:0.3f}  pan:{track_params[1]:0.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "a3fa5f622e0c4f19de725eca262006d4f26f3d54faeda6e10ceb975b2274f74b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
